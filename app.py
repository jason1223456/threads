import requests
import psycopg
from psycopg.rows import dict_row
from flask import Flask
from apscheduler.schedulers.background import BackgroundScheduler
from datetime import datetime, timedelta, timezone
import smtplib
from email.mime.text import MIMEText
from email.header import Header

# =======================================================
# Email è¨­å®š (Gmail App Password)
# =======================================================
SMTP_USER = "jason91082500@gmail.com"
SMTP_PASS = "rwundvtaybzrgzlz"   # è«‹æŠŠä½ çš„ APP å¯†ç¢¼è²¼åœ¨é€™
EMAIL_TO = "leona@brainmax-marketing.com"

def send_email(subject, body):
    try:
        msg = MIMEText(body.encode("utf-8"), "plain", "utf-8")
        msg["Subject"] = Header(subject, "utf-8")
        msg["From"] = Header(SMTP_USER, "utf-8")
        msg["To"] = Header(EMAIL_TO, "utf-8")

        server = smtplib.SMTP_SSL("smtp.gmail.com", 465)
        server.login(SMTP_USER, SMTP_PASS)
        server.sendmail(SMTP_USER, [EMAIL_TO], msg.as_string())
        server.quit()

        print("ğŸ“§ Email å¯„é€æˆåŠŸ")

    except Exception as e:
        print(f"âŒ Email å¯„é€å¤±æ•—ï¼š {e}")

# =======================================================
# API TOKEN
# =======================================================
API_TOKEN = "bscU4YK22+OYofSoh105OuVJZAh4tsYWZhKawi7WKjY="
API_DOMAIN = "https://api.threadslytics.com/v1"
HEADERS = {"Authorization": f"Bearer {API_TOKEN}"}
TAIPEI_OFFSET = timedelta(hours=8)

# =======================================================
# PostgreSQL
# =======================================================
DATABASE_URL = (
    "postgresql://root:"
    "L2em9nY8K4PcxCuXV60tf1Hs5MG7j3Oz"
    "@sfo1.clusters.zeabur.com:30599/zeabur"
)

conn = psycopg.connect(DATABASE_URL, row_factory=dict_row)
cursor = conn.cursor()

# =======================================================
# API FUNCTIONS
# =======================================================
def get_keyword_groups():
    r = requests.get(f"{API_DOMAIN}/keyword-groups", headers=HEADERS)
    r.raise_for_status()
    return r.json()["data"]   # groupName åœ¨é€™è£¡

def get_posts_by_group(group_id):
    posts = []
    page = 1
    while True:
        r = requests.get(
            f"{API_DOMAIN}/keyword-groups/analytics/{group_id}",
            headers=HEADERS,
            params={"metricDays": 7, "page": page}
        )
        r.raise_for_status()
        chunk = r.json().get("posts", [])
        if not chunk:
            break
        posts.extend(chunk)
        page += 1
    return posts

def get_metrics(code):
    r = requests.get(
        f"{API_DOMAIN}/threads/post/metrics",
        headers=HEADERS,
        params={"code": code}
    )
    r.raise_for_status()
    return r.json().get("data", [])

# =======================================================
# METRICS NORMALIZATION
# =======================================================
def normalize_metrics(m):
    return {
        "likeCount": m.get("likeCount") or 0,
        "directReplyCount": m.get("directReplyCount") or 0,
        "shares": m.get("shares") or 0,
        "repostCount": m.get("repostCount") or 0
    }

def pick_best_metrics(metrics):
    if not metrics:
        return {"likeCount": 0, "directReplyCount": 0, "shares": 0, "repostCount": 0}
    for m in metrics:
        nm = normalize_metrics(m)
        if any([nm["likeCount"], nm["directReplyCount"], nm["shares"], nm["repostCount"]]):
            return nm
    return normalize_metrics(metrics[0])

# =======================================================
# DB FUNCTIONS
# =======================================================
def get_existing_post(permalink):
    try:
        cursor.execute("SELECT 1 FROM social_posts WHERE permalink=%s LIMIT 1", (permalink,))
        return cursor.fetchone()
    except:
        conn.rollback()
        return None

def upsert_post(post, metrics, group_name, result_list):
    try:
        post_time_utc = datetime.fromisoformat(post["postCreatedAt"].replace("Z", "+00:00"))
        post_time_taipei = (post_time_utc + TAIPEI_OFFSET).replace(tzinfo=None)
        now_taipei = (datetime.now(timezone.utc) + TAIPEI_OFFSET).replace(tzinfo=None)

        permalink = post["permalink"]
        existing = get_existing_post(permalink)

        record = {
            "group": group_name,
            "code": post["code"],
            "metrics": metrics
        }

        if existing:
            status = "æ›´æ–°"
            cursor.execute("""
                UPDATE social_posts
                SET 
                    keyword=%s,
                    content=%s,
                    poster_name=%s,
                    media_title='threads',
                    media_name='threads',
                    site='THREADS',
                    channel='threadså°ˆæ¡ˆ',
                    api_source='threadslytics',
                    threads_like_count=%s,
                    threads_comment_count=%s,
                    threads_share_count=%s,
                    threads_repost_count=%s,
                    threads_topic=%s,
                    updated_at=%s
                WHERE permalink=%s
            """, (
                post.get("keywordText"),
                post.get("caption"),
                post.get("username"),
                metrics["likeCount"],
                metrics["directReplyCount"],
                metrics["shares"],
                metrics["repostCount"],
                post.get("tagHeader"),
                now_taipei,
                permalink
            ))

        else:
            status = "æ–°å¢"
            cursor.execute("""
                INSERT INTO social_posts (
                    date, keyword, content, permalink, poster_name,
                    media_title, media_name, site, channel, api_source,
                    threads_like_count, threads_comment_count,
                    threads_share_count, threads_repost_count,
                    threads_topic, created_at, updated_at
                )
                VALUES (
                    %s, %s, %s, %s, %s,
                    'threads', 'threads', 'THREADS', 'threadså°ˆæ¡ˆ', 'threadslytics',
                    %s, %s, %s, %s,
                    %s, %s, %s
                )
            """, (
                post_time_taipei,
                post.get("keywordText"),
                post.get("caption"),
                permalink,
                post.get("username"),
                metrics["likeCount"],
                metrics["directReplyCount"],
                metrics["shares"],
                metrics["repostCount"],
                post.get("tagHeader"),
                now_taipei,
                now_taipei
            ))

        conn.commit()

        record["status"] = status
        result_list.append(record)

    except Exception as e:
        print("âŒ å¯«å…¥éŒ¯èª¤ â€” rollback")
        print(e)
        conn.rollback()

# =======================================================
# Email Format
# =======================================================
def format_email(group_name, records):
    body = f"ğŸ“Œ ç¾¤çµ„ï¼š{group_name}\n\n"
    for r in records:
        m = r["metrics"]
        body += (
            f"{'ğŸ†•' if r['status']=='æ–°å¢' else 'ğŸ”„'} {r['code']}\n"
            f"    ğŸ‘ {m['likeCount']}   ğŸ’¬ {m['directReplyCount']}   "
            f"â†—ï¸ {m['shares']}   ğŸ” {m['repostCount']}\n\n"
        )
    return body

# =======================================================
# æ‰‹å‹•åŒ¯å…¥ 10
# =======================================================
def manual_import_10():
    print("\n===== ğŸš€ æ‰‹å‹•åŒ¯å…¥ 10 ç­†è²¼æ–‡ =====")

    result_list = []
    total = 0

    for group in get_keyword_groups():
        group_name = group.get("groupName", "æœªçŸ¥ç¾¤çµ„")
        posts = get_posts_by_group(group["id"])

        for p in posts:
            if total >= 10:
                email_body = format_email(group_name, result_list)
                send_email("æ‰‹å‹•åŒ¯å…¥å®Œæˆï¼ˆå‰10ç­†ï¼‰", email_body)
                print("\nğŸ‰ å·²å®ŒæˆåŒ¯å…¥ 10 ç­†")
                return

            metrics = pick_best_metrics(get_metrics(p["code"]))
            upsert_post(p, metrics, group_name, result_list)
            total += 1

    # æ‰€æœ‰éƒ½è™•ç†å®Œæ‰å¯„ä¿¡
    email_body = format_email("å…¨éƒ¨ç¾¤çµ„", result_list)
    send_email("æ‰‹å‹•åŒ¯å…¥å®Œæˆï¼ˆä¸åˆ°10ç­†ï¼‰", email_body)

# =======================================================
# æ¯å°æ™‚æ’ç¨‹ï¼šæŠ“å‰ 3ï½2 å°æ™‚è²¼æ–‡
# =======================================================
def job_import_last_2_to_3_hours():
    print("\nâ° æ¯å°æ™‚æ’ç¨‹é–‹å§‹")

    now = datetime.now(timezone.utc)
    start_time = now - timedelta(hours=3)
    end_time = now - timedelta(hours=2)

    result_list = []

    for group in get_keyword_groups():
        group_name = group.get("groupName", "æœªçŸ¥ç¾¤çµ„")
        for p in get_posts_by_group(group["id"]):
            t = datetime.fromisoformat(p["postCreatedAt"].replace("Z", "+00:00"))
            if start_time <= t <= end_time:
                metrics = pick_best_metrics(get_metrics(p["code"]))
                upsert_post(p, metrics, group_name, result_list)

    # æ’ç¨‹ä¸€æ¬¡å¯„ä¸€å°
    if result_list:
        send_email("æ¯å°æ™‚ Threads æ›´æ–°é€šçŸ¥", format_email("æ’ç¨‹æ›´æ–°", result_list))

# =======================================================
# Flask + Scheduler
# =======================================================
app = Flask(__name__)
scheduler = BackgroundScheduler()

scheduler.add_job(job_import_last_2_to_3_hours, "cron", minute=0)
scheduler.add_job(manual_import_10, "date", run_date=datetime.utcnow() + timedelta(seconds=5))
scheduler.start()

@app.route("/health")
def health():
    return "OK", 200

@app.route("/")
def index():
    return "Threads SocialPosts Crawler Running"

if __name__ == "__main__":
    manual_import_10()
    app.run(host="0.0.0.0", port=5000)
