import requests
import psycopg
from psycopg.rows import dict_row
from flask import Flask
from apscheduler.schedulers.background import BackgroundScheduler
from datetime import datetime, timedelta, timezone

import smtplib
from email.mime.text import MIMEText
from email.header import Header

# =======================================================
# âœ‰ï¸ Email è¨­å®š
# =======================================================
SMTP_SERVER = "smtp.gmail.com"
SMTP_PORT = 587
SMTP_USER = "jason91082500@gmail.com"

# é€™è£¡ä¿ç•™ä½ åŸæœ¬çœ‹åˆ°æœ‰ç©ºæ ¼çš„æ ¼å¼ï¼Œç¨‹å¼è‡ªå‹•å»ç©ºç™½
RAW_SMTP_PASS = "rwun dvta ybzr gzlz"
SMTP_PASS = RAW_SMTP_PASS.replace(" ", "").replace("\u00a0", "")

REPORT_RECEIVER = "leona@brainmax-marketing.com"


def send_email(subject: str, body: str):
    """å¯„å‡ºç´”æ–‡å­— Emailï¼ˆUTF-8ï¼‰"""
    subject = (subject or "").replace("\xa0", " ")
    body = (body or "").replace("\xa0", " ")

    try:
        msg = MIMEText(body, "plain", "utf-8")
        msg["From"] = SMTP_USER
        msg["To"] = REPORT_RECEIVER
        msg["Subject"] = Header(subject, "utf-8")

        smtp = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)
        smtp.starttls()
        smtp.login(SMTP_USER, SMTP_PASS)
        smtp.send_message(msg)
        smtp.quit()

        print(f"ğŸ“§ Email å¯„é€æˆåŠŸï¼š{subject}")
    except Exception as e:
        print("âŒ Email å¯„é€å¤±æ•—ï¼š", e)


# =======================================================
# Threadslytics API è¨­å®š
# =======================================================
API_TOKEN = "bscU4YK22+OYofSoh105OuVJZAh4tsYWZhKawi7WKjY="
API_DOMAIN = "https://api.threadslytics.com/v1"
HEADERS = {"Authorization": f"Bearer {API_TOKEN}"}

TAIPEI_OFFSET = timedelta(hours=8)

# =======================================================
# PostgreSQL è¨­å®š
# =======================================================
DATABASE_URL = (
    "postgresql://root:"
    "L2em9nY8K4PcxCuXV60tf1Hs5MG7j3Oz"
    "@sfo1.clusters.zeabur.com:30599/zeabur"
)

conn = psycopg.connect(DATABASE_URL, row_factory=dict_row)
cursor = conn.cursor()


# =======================================================
# API FUNCTIONS
# =======================================================
def get_keyword_groups():
    r = requests.get(f"{API_DOMAIN}/keyword-groups", headers=HEADERS)
    r.raise_for_status()
    return r.json()["data"]


def get_posts_by_group(group_id):
    posts = []
    page = 1
    while True:
        r = requests.get(
            f"{API_DOMAIN}/keyword-groups/analytics/{group_id}",
            headers=HEADERS,
            params={"metricDays": 7, "page": page}
        )
        r.raise_for_status()
        chunk = r.json().get("posts", [])
        if not chunk:
            break
        posts.extend(chunk)
        page += 1
    return posts


def get_metrics(code):
    r = requests.get(
        f"{API_DOMAIN}/threads/post/metrics",
        headers=HEADERS,
        params={"code": code}
    )
    r.raise_for_status()
    return r.json().get("data", [])


# =======================================================
# METRICS æ­£è¦åŒ–
# =======================================================
def normalize_metrics(m):
    return {
        "likeCount": m.get("likeCount") or 0,
        "directReplyCount": m.get("directReplyCount") or 0,
        "shares": m.get("shares") or 0,
        "repostCount": m.get("repostCount") or 0
    }


def pick_best_metrics(metrics):
    if not metrics:
        return {"likeCount": 0, "directReplyCount": 0, "shares": 0, "repostCount": 0}

    for m in metrics:
        nm = normalize_metrics(m)
        if any(nm.values()):
            return nm

    return normalize_metrics(metrics[0])


# =======================================================
# DB FUNCTIONS â€” channel='threadså°ˆæ¡ˆ' + api_source='threadslytics'
# =======================================================
def get_existing_post(permalink):
    try:
        cursor.execute(
            "SELECT 1 FROM social_posts WHERE permalink=%s LIMIT 1",
            (permalink,)
        )
        return cursor.fetchone()
    except Exception as e:
        print("âŒ æŸ¥ existing_post éŒ¯èª¤ï¼š", e)
        conn.rollback()
        return None


def upsert_post(post, metrics):
    """
    è™•ç†å–®ä¸€è²¼æ–‡ï¼Œå›å‚³ï¼š
      'insert' / 'update' / 'fail'
    """
    try:
        post_time_utc = datetime.fromisoformat(
            post["postCreatedAt"].replace("Z", "+00:00")
        )
        post_time_taipei = (post_time_utc + TAIPEI_OFFSET).replace(tzinfo=None)
        now_taipei = (datetime.now(timezone.utc) + TAIPEI_OFFSET).replace(tzinfo=None)

        permalink = post["permalink"]
        existing = get_existing_post(permalink)

        if existing:
            # ===== UPDATE =====
            cursor.execute("""
                UPDATE social_posts
                SET keyword=%s,
                    content=%s,
                    poster_name=%s,
                    media_title='threads',
                    media_name='threads',
                    site='THREADS',
                    channel='threadså°ˆæ¡ˆ',
                    api_source='threadslytics',
                    threads_like_count=%s,
                    threads_comment_count=%s,
                    threads_share_count=%s,
                    threads_repost_count=%s,
                    threads_topic=%s,
                    updated_at=%s
                WHERE permalink=%s
            """, (
                post.get("keywordText"),
                post.get("caption"),
                post.get("username"),
                metrics["likeCount"],
                metrics["directReplyCount"],
                metrics["shares"],
                metrics["repostCount"],
                post.get("tagHeader"),
                now_taipei,
                permalink
            ))
            conn.commit()
            return "update"

        # ===== INSERT =====
        cursor.execute("""
            INSERT INTO social_posts (
                date, keyword, content, permalink, poster_name,
                media_title, media_name, site, channel, api_source,
                threads_like_count, threads_comment_count,
                threads_share_count, threads_repost_count,
                threads_topic, created_at, updated_at
            )
            VALUES (%s,%s,%s,%s,%s,
                    'threads','threads','THREADS','threadså°ˆæ¡ˆ','threadslytics',
                    %s,%s,%s,%s,
                    %s,%s,%s)
        """, (
            post_time_taipei,
            post.get("keywordText"),
            post.get("caption"),
            permalink,
            post.get("username"),
            metrics["likeCount"],
            metrics["directReplyCount"],
            metrics["shares"],
            metrics["repostCount"],
            post.get("tagHeader"),
            now_taipei,
            now_taipei
        ))
        conn.commit()
        return "insert"

    except Exception as e:
        print("âŒ å¯«å…¥éŒ¯èª¤ â€” rollbackï¼š", e)
        conn.rollback()
        return "fail"


# =======================================================
# æ‰‹å‹•åŒ¯å…¥å‰ 10 ç­†ï¼ˆçµæŸå¯„ä¸€å°æ‘˜è¦ä¿¡ï¼ŒæŒ‰ groupName çµ±è¨ˆï¼‰
# =======================================================
def manual_import_10():
    print("\n===== ğŸš€ æ‰‹å‹•åŒ¯å…¥ 10 ç­†è²¼æ–‡ â†’ social_posts =====")

    # groupName -> {'insert': x, 'update': y, 'total': z}
    group_stats = {}
    total = 0

    groups = get_keyword_groups()

    for group in groups:
        group_name = group.get("groupName", "æœªçŸ¥ç¾¤çµ„")  # â­ ç”¨ groupName
        posts = get_posts_by_group(group["id"])

        for p in posts:
            if total >= 10:
                break

            metrics = pick_best_metrics(get_metrics(p["code"]))
            result = upsert_post(p, metrics)

            if group_name not in group_stats:
                group_stats[group_name] = {"insert": 0, "update": 0, "total": 0}

            if result == "insert":
                group_stats[group_name]["insert"] += 1
            elif result == "update":
                group_stats[group_name]["update"] += 1

            group_stats[group_name]["total"] += 1
            total += 1

            print(f"âœ… ç¬¬ {total} ç­†ï¼š{p['code']}ï¼ˆç¾¤çµ„ï¼š{group_name}ï¼Œçµæœï¼š{result}ï¼‰")

        if total >= 10:
            break

    # çµ„ Email å…§å®¹
    lines = []
    lines.append("ã€æ‰‹å‹•åŒ¯å…¥å‰ 10 ç­†è²¼æ–‡çµæœã€‘\n")

    if not group_stats:
        lines.append("æœ¬æ¬¡æ²’æœ‰ä»»ä½•è²¼æ–‡è¢«è™•ç†ã€‚")
    else:
        for name, stat in group_stats.items():
            lines.append(f"ğŸ” é—œéµå­—ç¾¤çµ„ï¼š{name}")
            lines.append(f"  ğŸ“Œ ç¸½è™•ç†ï¼š{stat['total']} ç­†")
            lines.append(f"  ğŸ†• æ–°å¢ï¼š{stat['insert']} ç­†")
            lines.append(f"  ğŸ”„ æ›´æ–°ï¼š{stat['update']} ç­†\n")

    body = "\n".join(lines)
    send_email("Threads æ‰‹å‹•åŒ¯å…¥å‰ 10 ç­†æ‘˜è¦ï¼ˆä¾é—œéµå­—ç¾¤çµ„ï¼‰", body)

    print("\nğŸ‰ æ‰‹å‹•åŒ¯å…¥å®Œæˆï¼Œå·²å¯„å‡ºæ‘˜è¦ email")


# =======================================================
# æ¯å°æ™‚ï¼šæŠ“å‰ 3ï½2 å°æ™‚çš„è²¼æ–‡ï¼ˆä¾ groupName çµ±è¨ˆï¼‰
# =======================================================
def job_import_last_2_to_3_hours():
    print("\n===== â° æ¯å°æ™‚ Threads åŒ¯å…¥ä»»å‹™é–‹å§‹ =====")

    now = datetime.now(timezone.utc)
    start_time = now - timedelta(hours=3)
    end_time = now - timedelta(hours=2)

    groups = get_keyword_groups()

    lines = []
    lines.append(f"æ™‚é–“å€é–“ï¼ˆUTCï¼‰ï¼š{start_time} ï½ {end_time}\n")

    for group in groups:
        group_name = group.get("groupName", "æœªçŸ¥ç¾¤çµ„")  # â­ ç”¨ groupName
        posts = get_posts_by_group(group["id"])

        group_insert = 0
        group_update = 0
        group_total = 0

        # ç¯©é¸æ™‚é–“å€é–“å…§çš„è²¼æ–‡
        filtered = []
        for p in posts:
            t = datetime.fromisoformat(p["postCreatedAt"].replace("Z", "+00:00"))
            if start_time <= t <= end_time:
                filtered.append(p)

        # æ²’æœ‰è²¼æ–‡
        if not filtered:
            lines.append(f"ğŸ” é—œéµå­—ç¾¤çµ„ï¼š{group_name}")
            lines.append("  âš ï¸ é€™å€‹æ™‚é–“å€é–“å…§æ²’æœ‰è²¼æ–‡ï¼Œä¸å¯«å…¥è³‡æ–™åº«\n")
            continue

        # æœ‰è²¼æ–‡ â†’ å¯«å…¥
        for p in filtered:
            metrics = pick_best_metrics(get_metrics(p["code"]))
            result = upsert_post(p, metrics)

            if result == "insert":
                group_insert += 1
            elif result == "update":
                group_update += 1

            group_total += 1

        lines.append(f"ğŸ” é—œéµå­—ç¾¤çµ„ï¼š{group_name}")
        lines.append(f"  ğŸ“Œ æ™‚æ®µå…§è²¼æ–‡æ•¸ï¼š{group_total}")
        lines.append(f"  ğŸ†• æ–°å¢ï¼š{group_insert}")
        lines.append(f"  ğŸ”„ æ›´æ–°ï¼š{group_update}\n")

    body = "\n".join(lines)
    send_email("Threads æ¯å°æ™‚åŒ¯å…¥æ‘˜è¦ï¼ˆä¾é—œéµå­—ç¾¤çµ„ï¼‰", body)

    print("ğŸ‰ æ¯å°æ™‚ä»»å‹™å®Œæˆï¼Œå·²å¯„å‡ºæ‘˜è¦ email")


# =======================================================
# Flask + æ’ç¨‹
# =======================================================
app = Flask(__name__)
scheduler = BackgroundScheduler()

# æ¯å°æ™‚æ•´é»è·‘ä¸€æ¬¡
scheduler.add_job(job_import_last_2_to_3_hours, "cron", minute=0)

# å•Ÿå‹•å¾Œ 5 ç§’å…ˆæ‰‹å‹•åŒ¯å…¥ 10 ç­†ï¼ˆæ–¹ä¾¿æ¸¬è©¦ï¼‰
scheduler.add_job(
    manual_import_10,
    "date",
    run_date=datetime.utcnow() + timedelta(seconds=5)
)

scheduler.start()


@app.route("/health")
def health():
    return "OK", 200


@app.route("/")
def index():
    return "Threads SocialPosts Crawler Running"


if __name__ == "__main__":
    # æœ¬åœ°åŸ·è¡Œæ™‚ä¹Ÿæœƒå…ˆè·‘ä¸€æ¬¡æ‰‹å‹• 10 ç­†
    manual_import_10()
    app.run(host="0.0.0.0", port=5000)
